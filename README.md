# üõ°Ô∏è IDS MLOps - Syst√®me de D√©tection d'Intrusions

Un syst√®me complet de d√©tection d'intrusions r√©seau utilisant des techniques de Machine Learning avec un pipeline MLOps automatis√©.

## üéØ Aper√ßu du Projet

Ce projet impl√©mente un syst√®me de d√©tection d'intrusions (IDS) intelligent capable de :
- **D√©tecter automatiquement** les attaques r√©seau en temps r√©el
- **Classifier** le trafic normal vs malveillant avec >99% de pr√©cision
- **Identifier** diff√©rents types d'attaques (DoS, Probe, R2L, U2R)
- **Monitorer** et am√©liorer continuellement les performances

### üìä Performances Actuelles
- **Precision** : 99.91%
- **Recall** : 99.72% (seulement 33 attaques manqu√©es sur 11,726)
- **F1-Score** : 99.82%
- **Latence** : <1ms par pr√©diction

## üèóÔ∏è Architecture

```
‚îú‚îÄ‚îÄ data/                    # Donn√©es du projet
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Datasets originaux (NSL-KDD)
‚îÇ   ‚îî‚îÄ‚îÄ processed/           # Donn√©es pr√©trait√©es
‚îú‚îÄ‚îÄ src/                     # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py # Pipeline de nettoyage des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Scripts ML
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # Utilitaires
‚îú‚îÄ‚îÄ notebooks/               # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 02_preprocessing_baseline.ipynb
‚îú‚îÄ‚îÄ models/                  # Mod√®les sauvegard√©s
‚îú‚îÄ‚îÄ mlruns/                  # MLflow tracking
‚îî‚îÄ‚îÄ requirements.txt         # D√©pendances Python
```

## üöÄ Installation et Utilisation

### Pr√©requis
- Python 3.8+
- pip ou conda

### 1. Cloner le projet
```bash
git clone <votre-repo>
cd ids-mlops-project
```

### 2. Cr√©er l'environnement virtuel
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux  
source venv/bin/activate
```

### 3. Installer les d√©pendances
```bash
pip install -r requirements.txt
```

### 4. T√©l√©charger les donn√©es
T√©l√©chargez le dataset NSL-KDD depuis [UNB](https://www.unb.ca/cic/datasets/nsl.html) :
- `KDDTrain+.txt` ‚Üí `data/raw/`
- `KDDTest+.txt` ‚Üí `data/raw/`

### 5. Reproduire les r√©sultats
```bash
# Lancer MLflow UI (dans un terminal s√©par√©)
mlflow ui

# Ex√©cuter les notebooks dans l'ordre
jupyter notebook
# 1. notebooks/01_data_exploration.ipynb
# 2. notebooks/02_preprocessing_baseline.ipynb
```

## üìà Pipeline ML

### 1. Exploration des Donn√©es (EDA)
- **125,973 √©chantillons** d'entra√Ænement
- **23 types d'attaques** diff√©rents
- **41 features** num√©riques et cat√©gorielles
- Identification des **features discriminantes**

### 2. Preprocessing
- **Nettoyage** : Suppression des features constantes et creuses
- **Encoding** : One-hot encoding pour les variables cat√©gorielles
- **Transformation** : Log-transformation pour g√©rer les outliers
- **Scaling** : StandardScaler pour les features num√©riques

### 3. Mod√©lisation
- **Algorithme** : Random Forest avec class weights
- **Optimisation** : Maximisation du recall (d√©tection d'attaques)
- **Validation** : Train/test split avec stratification

### 4. MLOps
- **Tracking** : MLflow pour l'exp√©rimentation
- **Registry** : Versioning des mod√®les
- **Reproductibilit√©** : Seeds fix√©s et environment sauvegard√©

## üîß Utilisation du Mod√®le

### Chargement depuis MLflow
```python
import mlflow.sklearn

# Charger le mod√®le de production
model_uri = "models:/IDS_RandomForest_Production/latest"
model = mlflow.sklearn.load_model(model_uri)

# Pr√©diction
prediction = model.predict(X_new)
```

### Preprocessing des nouvelles donn√©es
```python
from src.data.preprocessing import clean_dataset, prepare_for_ml

# Nettoyer les nouvelles donn√©es
df_clean, features = clean_dataset(new_data, target_binary=True)

# Pr√©parer pour la pr√©diction
X_new = df_clean[features]
```

## üìä R√©sultats D√©taill√©s

### Performance par Type d'Attaque
| Cat√©gorie | √âchantillons | Taux D√©tection |
|-----------|--------------|----------------|
| Normal    | 13,469       | 99.88%         |
| DoS       | 9,234        | 99.85%         |
| Probe     | 2,289        | 99.43%         |
| R2L       | 198          | 97.47%         |
| U2R       | 11           | 90.91%         |

### Features les Plus Importantes
1. **dst_bytes_log** (16.69%) - Bytes de destination
2. **src_bytes_log** (15.75%) - Bytes source  
3. **flag_SF** (13.47%) - Status de connexion
4. **same_srv_rate** (7.97%) - Taux m√™me service
5. **dst_host_srv_count** (6.13%) - Compteur connexions

## üõ†Ô∏è Technologies Utilis√©es

- **Python 3.8+** - Langage principal
- **Scikit-learn** - Machine Learning
- **MLflow** - Tracking et registry
- **Pandas/NumPy** - Manipulation des donn√©es
- **Matplotlib/Seaborn** - Visualisations
- **Jupyter** - D√©veloppement interactif

## üìÅ Structure des Donn√©es

### Dataset NSL-KDD
- **Source** : Canadian Institute for Cybersecurity
- **Type** : Trafic r√©seau √©tiquet√©
- **Features** : 41 caract√©ristiques par connexion
- **Classes** : Normal + 4 types d'attaques

### Features Principales
- **Connexion** : dur√©e, protocole, service, flag
- **Contenu** : bytes √©chang√©s, tentatives de login
- **Trafic** : compteurs, taux d'erreur
- **H√¥te** : statistiques par destination

## üîÆ √âvolutions Futures

### Phase 1 - API de Production
- [ ] API FastAPI pour serving en temps r√©el
- [ ] Documentation Swagger automatique
- [ ] Tests unitaires et d'int√©gration

### Phase 2 - Monitoring Avanc√©
- [ ] D√©tection de d√©rive des donn√©es
- [ ] Alertes automatiques Slack/Email
- [ ] Dashboard Grafana temps r√©el

### Phase 3 - D√©ploiement Cloud
- [ ] Containerisation Docker
- [ ] Orchestration Kubernetes
- [ ] CI/CD avec GitHub Actions

## ü§ù Contribution

1. **Fork** le projet
2. **Cr√©ez** une branche feature (`git checkout -b feature/improvement`)
3. **Committez** vos changements (`git commit -m 'Add improvement'`)
4. **Push** vers la branche (`git push origin feature/improvement`)
5. **Ouvrez** une Pull Request

## üìù License

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üôè Remerciements

- **NSL-KDD Dataset** - University of New Brunswick
- **MLflow** - Databricks pour l'excellent outil MLOps
- **Scikit-learn** - Pour les algorithmes ML robustes

## üìû Contact

**Yassine HANDANE**
- üìß Email : y.handane@gmail.com
- üíº LinkedIn : [Yassine HANDANE](https://linkedin.com/in/yassine-handane)
- üêô GitHub : [YsnHdn](https://github.com/YsnHdn)

---

‚≠ê **Si ce projet vous aide, n'h√©sitez pas √† lui donner une √©toile !**